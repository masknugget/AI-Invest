"""
æ¨¡å‹èƒ½åŠ›åˆ†çº§ç³»ç»Ÿ

å®šä¹‰æ¨¡å‹çš„èƒ½åŠ›ç­‰çº§ã€é€‚ç”¨è§’è‰²ã€ç‰¹æ€§æ ‡ç­¾ç­‰å…ƒæ•°æ®ï¼Œ
ç”¨äºæ™ºèƒ½åŒ¹é…åˆ†ææ·±åº¦å’Œæ¨¡å‹é€‰æ‹©ã€‚

ğŸ†• èšåˆæ¸ é“æ”¯æŒï¼š
- æ”¯æŒ 302.AIã€OpenRouterã€One API ç­‰èšåˆæ¸ é“
- èšåˆæ¸ é“çš„æ¨¡å‹åç§°æ ¼å¼ï¼š{provider}/{model}ï¼ˆå¦‚ openai/gpt-4ï¼‰
- ç³»ç»Ÿä¼šè‡ªåŠ¨æ˜ å°„åˆ°åŸå‚æ¨¡å‹çš„èƒ½åŠ›é…ç½®
"""

from enum import IntEnum, Enum
from typing import Dict, List, Any, Tuple


class ModelCapabilityLevel(IntEnum):
    """æ¨¡å‹èƒ½åŠ›ç­‰çº§ï¼ˆ1-5çº§ï¼‰"""
    BASIC = 1  # åŸºç¡€ï¼šé€‚åˆ1-2çº§åˆ†æï¼Œè½»é‡å¿«é€Ÿ
    STANDARD = 2  # æ ‡å‡†ï¼šé€‚åˆ1-3çº§åˆ†æï¼Œæ—¥å¸¸ä½¿ç”¨
    ADVANCED = 3  # é«˜çº§ï¼šé€‚åˆ1-4çº§åˆ†æï¼Œå¤æ‚æ¨ç†
    PROFESSIONAL = 4  # ä¸“ä¸šï¼šé€‚åˆ1-5çº§åˆ†æï¼Œä¸“ä¸šçº§åˆ†æ
    FLAGSHIP = 5  # æ——èˆ°ï¼šé€‚åˆæ‰€æœ‰çº§åˆ«ï¼Œæœ€å¼ºèƒ½åŠ›


class ModelRole(str, Enum):
    """æ¨¡å‹è§’è‰²ç±»å‹"""
    QUICK_ANALYSIS = "quick_analysis"  # å¿«é€Ÿåˆ†æï¼ˆæ•°æ®æ”¶é›†ã€å·¥å…·è°ƒç”¨ï¼‰
    DEEP_ANALYSIS = "deep_analysis"  # æ·±åº¦åˆ†æï¼ˆæ¨ç†ã€å†³ç­–ï¼‰
    BOTH = "both"  # ä¸¤è€…éƒ½é€‚åˆ


class ModelFeature(str, Enum):
    """æ¨¡å‹ç‰¹æ€§æ ‡ç­¾"""
    TOOL_CALLING = "tool_calling"  # æ”¯æŒå·¥å…·è°ƒç”¨ï¼ˆå¿…éœ€ï¼‰
    LONG_CONTEXT = "long_context"  # æ”¯æŒé•¿ä¸Šä¸‹æ–‡
    REASONING = "reasoning"  # å¼ºæ¨ç†èƒ½åŠ›
    VISION = "vision"  # æ”¯æŒè§†è§‰è¾“å…¥
    FAST_RESPONSE = "fast_response"  # å¿«é€Ÿå“åº”
    COST_EFFECTIVE = "cost_effective"  # æˆæœ¬æ•ˆç›Šé«˜


# èƒ½åŠ›ç­‰çº§æè¿°
CAPABILITY_DESCRIPTIONS = {
    1: "åŸºç¡€æ¨¡å‹ - é€‚åˆå¿«é€Ÿåˆ†æå’Œç®€å•ä»»åŠ¡ï¼Œå“åº”å¿«é€Ÿï¼Œæˆæœ¬ä½",
    2: "æ ‡å‡†æ¨¡å‹ - é€‚åˆæ—¥å¸¸åˆ†æå’Œå¸¸è§„ä»»åŠ¡ï¼Œå¹³è¡¡æ€§èƒ½å’Œæˆæœ¬",
    3: "é«˜çº§æ¨¡å‹ - é€‚åˆæ·±åº¦åˆ†æå’Œå¤æ‚æ¨ç†ï¼Œè´¨é‡è¾ƒé«˜",
    4: "ä¸“ä¸šæ¨¡å‹ - é€‚åˆä¸“ä¸šçº§åˆ†æå’Œå¤šè½®è¾©è®ºï¼Œé«˜è´¨é‡è¾“å‡º",
    5: "æ——èˆ°æ¨¡å‹ - æœ€å¼ºèƒ½åŠ›ï¼Œé€‚åˆå…¨é¢åˆ†æå’Œå…³é”®å†³ç­–"
}

# åˆ†ææ·±åº¦è¦æ±‚çš„æœ€ä½èƒ½åŠ›ç­‰çº§
ANALYSIS_DEPTH_REQUIREMENTS = {
    "å¿«é€Ÿ": {
        "min_capability": 1,
        "quick_model_min": 1,
        "deep_model_min": 1,
        "required_features": [ModelFeature.TOOL_CALLING],
        "description": "1çº§å¿«é€Ÿåˆ†æï¼šä»»ä½•æ¨¡å‹éƒ½å¯ä»¥ï¼Œä¼˜å…ˆé€‰æ‹©å¿«é€Ÿå“åº”çš„æ¨¡å‹"
    },
    "åŸºç¡€": {
        "min_capability": 1,
        "quick_model_min": 1,
        "deep_model_min": 2,
        "required_features": [ModelFeature.TOOL_CALLING],
        "description": "2çº§åŸºç¡€åˆ†æï¼šå¿«é€Ÿæ¨¡å‹å¯ç”¨åŸºç¡€çº§ï¼Œæ·±åº¦æ¨¡å‹å»ºè®®æ ‡å‡†çº§ä»¥ä¸Š"
    },
    "æ ‡å‡†": {
        "min_capability": 2,
        "quick_model_min": 1,
        "deep_model_min": 2,
        "required_features": [ModelFeature.TOOL_CALLING],
        "description": "3çº§æ ‡å‡†åˆ†æï¼šå¿«é€Ÿæ¨¡å‹å¯ç”¨åŸºç¡€çº§ï¼Œæ·±åº¦æ¨¡å‹éœ€è¦æ ‡å‡†çº§ä»¥ä¸Š"
    },
    "æ·±åº¦": {
        "min_capability": 3,
        "quick_model_min": 2,
        "deep_model_min": 3,
        "required_features": [ModelFeature.TOOL_CALLING, ModelFeature.REASONING],
        "description": "4çº§æ·±åº¦åˆ†æï¼šå¿«é€Ÿæ¨¡å‹éœ€æ ‡å‡†çº§ï¼Œæ·±åº¦æ¨¡å‹éœ€é«˜çº§ä»¥ä¸Šï¼Œéœ€è¦æ¨ç†èƒ½åŠ›"
    },
    "å…¨é¢": {
        "min_capability": 4,
        "quick_model_min": 2,
        "deep_model_min": 4,
        "required_features": [ModelFeature.TOOL_CALLING, ModelFeature.REASONING],
        "description": "5çº§å…¨é¢åˆ†æï¼šå¿«é€Ÿæ¨¡å‹éœ€æ ‡å‡†çº§ï¼Œæ·±åº¦æ¨¡å‹éœ€ä¸“ä¸šçº§ä»¥ä¸Šï¼Œå¼ºæ¨ç†èƒ½åŠ›"
    }
}

# å¸¸è§æ¨¡å‹çš„é»˜è®¤èƒ½åŠ›é…ç½®ï¼ˆç”¨äºåˆå§‹åŒ–å’Œå‚è€ƒï¼‰
DEFAULT_MODEL_CAPABILITIES: Dict[str, Dict[str, Any]] = {
    # ==================== OpenAI ====================
    "gpt-3.5-turbo": {
        "capability_level": 1,
        "suitable_roles": [ModelRole.QUICK_ANALYSIS],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.FAST_RESPONSE, ModelFeature.COST_EFFECTIVE],
        "recommended_depths": ["å¿«é€Ÿ", "åŸºç¡€"],
        "performance_metrics": {"speed": 5, "cost": 5, "quality": 3},
        "description": "GPT-3.5 Turboï¼Œå¿«é€Ÿä¸”ç»æµ"
    },
    "gpt-4": {
        "capability_level": 3,
        "suitable_roles": [ModelRole.BOTH],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.REASONING],
        "recommended_depths": ["åŸºç¡€", "æ ‡å‡†", "æ·±åº¦"],
        "performance_metrics": {"speed": 3, "cost": 3, "quality": 4},
        "description": "GPT-4ï¼Œå¼ºå¤§çš„æ¨ç†èƒ½åŠ›"
    },
    "gpt-4-turbo": {
        "capability_level": 4,
        "suitable_roles": [ModelRole.BOTH],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.LONG_CONTEXT, ModelFeature.REASONING, ModelFeature.VISION],
        "recommended_depths": ["æ ‡å‡†", "æ·±åº¦", "å…¨é¢"],
        "performance_metrics": {"speed": 4, "cost": 2, "quality": 5},
        "description": "GPT-4 Turboï¼Œæ›´å¿«æ›´å¼º"
    },
    "gpt-4o-mini": {
        "capability_level": 2,
        "suitable_roles": [ModelRole.BOTH],
        "features": [ModelFeature.TOOL_CALLING, ModelFeature.FAST_RESPONSE, ModelFeature.COST_EFFECTIVE],
        "recommended_depths": ["å¿«é€Ÿ", "åŸºç¡€", "æ ‡å‡†"],
        "performance_metrics": {"speed": 5, "cost": 5, "quality": 3},
        "description": "GPT-4o Miniï¼Œç»æµå®æƒ "
    },
    "o1-mini": {
        "capability_level": 4,
        "suitable_roles": [ModelRole.DEEP_ANALYSIS],
        "features": [ModelFeature.REASONING],
        "recommended_depths": ["æ·±åº¦", "å…¨é¢"],
        "performance_metrics": {"speed": 2, "cost": 3, "quality": 5},
        "description": "O1 Miniï¼Œå¼ºæ¨ç†æ¨¡å‹"
    },
    "o1": {
        "capability_level": 5,
        "suitable_roles": [ModelRole.DEEP_ANALYSIS],
        "features": [ModelFeature.REASONING],
        "recommended_depths": ["å…¨é¢"],
        "performance_metrics": {"speed": 1, "cost": 1, "quality": 5},
        "description": "O1ï¼Œæœ€å¼ºæ¨ç†èƒ½åŠ›"
    },
    "o4-mini": {
        "capability_level": 4,
        "suitable_roles": [ModelRole.DEEP_ANALYSIS],
        "features": [ModelFeature.REASONING],
        "recommended_depths": ["æ·±åº¦", "å…¨é¢"],
        "performance_metrics": {"speed": 2, "cost": 3, "quality": 5},
        "description": "O4 Miniï¼Œæ–°ä¸€ä»£æ¨ç†æ¨¡å‹"
    },
}


def get_model_capability_badge(level: int) -> Dict[str, str]:
    """è·å–èƒ½åŠ›ç­‰çº§å¾½ç« æ ·å¼"""
    badges = {
        1: {"text": "åŸºç¡€", "color": "#909399", "icon": "âš¡"},
        2: {"text": "æ ‡å‡†", "color": "#409EFF", "icon": "ğŸ“Š"},
        3: {"text": "é«˜çº§", "color": "#67C23A", "icon": "ğŸ¯"},
        4: {"text": "ä¸“ä¸š", "color": "#E6A23C", "icon": "ğŸ”¥"},
        5: {"text": "æ——èˆ°", "color": "#F56C6C", "icon": "ğŸ‘‘"}
    }
    return badges.get(level, badges[2])


def get_role_badge(role: ModelRole) -> Dict[str, str]:
    """è·å–è§’è‰²å¾½ç« æ ·å¼"""
    badges = {
        ModelRole.QUICK_ANALYSIS: {"text": "å¿«é€Ÿåˆ†æ", "color": "success", "icon": "âš¡"},
        ModelRole.DEEP_ANALYSIS: {"text": "æ·±åº¦æ¨ç†", "color": "warning", "icon": "ğŸ§ "},
        ModelRole.BOTH: {"text": "é€šç”¨", "color": "primary", "icon": "ğŸ¯"}
    }
    return badges.get(role, badges[ModelRole.BOTH])


def get_feature_badge(feature: ModelFeature) -> Dict[str, str]:
    """è·å–ç‰¹æ€§å¾½ç« æ ·å¼"""
    badges = {
        ModelFeature.TOOL_CALLING: {"text": "å·¥å…·è°ƒç”¨", "color": "info", "icon": "ğŸ”§"},
        ModelFeature.LONG_CONTEXT: {"text": "é•¿ä¸Šä¸‹æ–‡", "color": "success", "icon": "ğŸ“š"},
        ModelFeature.REASONING: {"text": "å¼ºæ¨ç†", "color": "warning", "icon": "ğŸ§ "},
        ModelFeature.VISION: {"text": "è§†è§‰", "color": "primary", "icon": "ğŸ‘ï¸"},
        ModelFeature.FAST_RESPONSE: {"text": "å¿«é€Ÿ", "color": "success", "icon": "âš¡"},
        ModelFeature.COST_EFFECTIVE: {"text": "ç»æµ", "color": "success", "icon": "ğŸ’°"}
    }
    return badges.get(feature, {"text": str(feature), "color": "info", "icon": "âœ¨"})


def is_aggregator_model(model_name: str) -> bool:
    """
    åˆ¤æ–­æ˜¯å¦ä¸ºèšåˆæ¸ é“æ¨¡å‹åç§°

    Args:
        model_name: æ¨¡å‹åç§°

    Returns:
        æ˜¯å¦ä¸ºèšåˆæ¸ é“æ¨¡å‹
    """
    return "/" in model_name


def parse_aggregator_model(model_name: str) -> Tuple[str, str]:
    """
    è§£æèšåˆæ¸ é“æ¨¡å‹åç§°

    Args:
        model_name: æ¨¡å‹åç§°ï¼ˆå¦‚ openai/gpt-4ï¼‰

    Returns:
        (provider, model) å…ƒç»„
    """
    if "/" in model_name:
        parts = model_name.split("/", 1)
        return parts[0], parts[1]
    return "", model_name
